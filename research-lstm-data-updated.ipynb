{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a285051",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-04-09T18:09:56.451584Z",
     "iopub.status.busy": "2024-04-09T18:09:56.450849Z",
     "iopub.status.idle": "2024-04-09T18:10:11.409383Z",
     "shell.execute_reply": "2024-04-09T18:10:11.408212Z"
    },
    "papermill": {
     "duration": 14.972762,
     "end_time": "2024-04-09T18:10:11.412590",
     "exception": false,
     "start_time": "2024-04-09T18:09:56.439828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/predict-student-performance-from-game-play/sample_submission.csv\n",
      "/kaggle/input/predict-student-performance-from-game-play/train_labels.csv\n",
      "/kaggle/input/predict-student-performance-from-game-play/train.csv\n",
      "/kaggle/input/predict-student-performance-from-game-play/test.csv\n",
      "/kaggle/input/predict-student-performance-from-game-play/jo_wilder_310/competition.cpython-310-x86_64-linux-gnu.so\n",
      "/kaggle/input/predict-student-performance-from-game-play/jo_wilder_310/__init__.py\n",
      "/kaggle/input/predict-student-performance-from-game-play/jo_wilder/competition.cpython-37m-x86_64-linux-gnu.so\n",
      "/kaggle/input/predict-student-performance-from-game-play/jo_wilder/__init__.py\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import f1_score,confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Bidirectional, LSTM, Dropout, BatchNormalization, TimeDistributed, Dense\n",
    "from keras.layers import Flatten\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19f54922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:10:11.429840Z",
     "iopub.status.busy": "2024-04-09T18:10:11.428741Z",
     "iopub.status.idle": "2024-04-09T18:10:11.458195Z",
     "shell.execute_reply": "2024-04-09T18:10:11.457277Z"
    },
    "papermill": {
     "duration": 0.040008,
     "end_time": "2024-04-09T18:10:11.460406",
     "exception": false,
     "start_time": "2024-04-09T18:10:11.420398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb6826a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:10:11.478100Z",
     "iopub.status.busy": "2024-04-09T18:10:11.477428Z",
     "iopub.status.idle": "2024-04-09T18:12:22.097328Z",
     "shell.execute_reply": "2024-04-09T18:12:22.096128Z"
    },
    "papermill": {
     "duration": 130.639869,
     "end_time": "2024-04-09T18:12:22.108401",
     "exception": false,
     "start_time": "2024-04-09T18:10:11.468532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full train dataset shape is (26296946, 20)\n"
     ]
    }
   ],
   "source": [
    "dtypes={\n",
    "    'elapsed_time':np.int32,\n",
    "    'event_name':'category',\n",
    "    'name':'category',\n",
    "    'level':np.uint8,\n",
    "    'room_coor_x':np.float32,\n",
    "    'room_coor_y':np.float32,\n",
    "    'screen_coor_x':np.float32,\n",
    "    'screen_coor_y':np.float32,\n",
    "    'hover_duration':np.float32,\n",
    "    'text':'category',\n",
    "    'fqid':'category',\n",
    "    'room_fqid':'category',\n",
    "    'text_fqid':'category',\n",
    "    'fullscreen':'category',\n",
    "    'hq':'category',\n",
    "    'music':'category',\n",
    "    'level_group':'category'}\n",
    "\n",
    "dataset_df = pd.read_csv('/kaggle/input/predict-student-performance-from-game-play/train.csv', dtype=dtypes)\n",
    "print(\"Full train dataset shape is {}\".format(dataset_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e4a91d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:12:22.127235Z",
     "iopub.status.busy": "2024-04-09T18:12:22.126317Z",
     "iopub.status.idle": "2024-04-09T18:12:23.533350Z",
     "shell.execute_reply": "2024-04-09T18:12:23.532458Z"
    },
    "papermill": {
     "duration": 1.419313,
     "end_time": "2024-04-09T18:12:23.536080",
     "exception": false,
     "start_time": "2024-04-09T18:12:22.116767",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = pd.read_csv('/kaggle/input/predict-student-performance-from-game-play/train_labels.csv')\n",
    "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
    "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "818b1515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:12:23.553005Z",
     "iopub.status.busy": "2024-04-09T18:12:23.552228Z",
     "iopub.status.idle": "2024-04-09T18:12:23.557918Z",
     "shell.execute_reply": "2024-04-09T18:12:23.557012Z"
    },
    "papermill": {
     "duration": 0.016337,
     "end_time": "2024-04-09T18:12:23.560049",
     "exception": false,
     "start_time": "2024-04-09T18:12:23.543712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Categorizing Features on the Type\n",
    "CATS = ['event_name', 'name','fqid', 'room_fqid', 'text_fqid']\n",
    "NUMS = ['elapsed_time','level','page','room_coor_x', 'room_coor_y', \n",
    "        'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
    "EVENTS = ['navigate_click','person_click','cutscene_click','object_click',\n",
    "          'map_hover','notification_click','map_click','observation_click',\n",
    "          'checkpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73245266",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:12:23.576005Z",
     "iopub.status.busy": "2024-04-09T18:12:23.575324Z",
     "iopub.status.idle": "2024-04-09T18:12:23.585808Z",
     "shell.execute_reply": "2024-04-09T18:12:23.584874Z"
    },
    "papermill": {
     "duration": 0.020872,
     "end_time": "2024-04-09T18:12:23.588016",
     "exception": false,
     "start_time": "2024-04-09T18:12:23.567144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineer(dataset_df):\n",
    "    dfs = []\n",
    "    for c in CATS:\n",
    "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('nunique')\n",
    "        tmp.name = tmp.name + '_nunique'\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMS:\n",
    "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('mean')\n",
    "        tmp.name = tmp.name + '_mean'\n",
    "        dfs.append(tmp)\n",
    "    for c in NUMS:\n",
    "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('std')\n",
    "        tmp.name = tmp.name + '_std'\n",
    "        dfs.append(tmp)\n",
    "    for c in EVENTS: \n",
    "        dataset_df[c] = (dataset_df.event_name == c).astype('int8')\n",
    "    for c in EVENTS + ['elapsed_time']:\n",
    "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('sum')\n",
    "        tmp.name = tmp.name + '_sum'\n",
    "        dfs.append(tmp)\n",
    "    dataset_df = dataset_df.drop(EVENTS,axis=1)\n",
    "        \n",
    "    dataset_df = pd.concat(dfs,axis=1)\n",
    "    dataset_df = dataset_df.fillna(-1)\n",
    "    dataset_df = dataset_df.reset_index()\n",
    "    dataset_df = dataset_df.set_index('session_id')\n",
    "    return dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d2cbc8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:12:23.604008Z",
     "iopub.status.busy": "2024-04-09T18:12:23.603644Z",
     "iopub.status.idle": "2024-04-09T18:13:15.155213Z",
     "shell.execute_reply": "2024-04-09T18:13:15.153793Z"
    },
    "papermill": {
     "duration": 51.570384,
     "end_time": "2024-04-09T18:13:15.166063",
     "exception": false,
     "start_time": "2024-04-09T18:12:23.595679",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape is (70686, 32)\n"
     ]
    }
   ],
   "source": [
    "dataset_df = feature_engineer(dataset_df)\n",
    "print(\"Dataset shape is {}\".format(dataset_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bc6111c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:13:15.183818Z",
     "iopub.status.busy": "2024-04-09T18:13:15.182845Z",
     "iopub.status.idle": "2024-04-09T18:13:15.188745Z",
     "shell.execute_reply": "2024-04-09T18:13:15.187714Z"
    },
    "papermill": {
     "duration": 0.017531,
     "end_time": "2024-04-09T18:13:15.191378",
     "exception": false,
     "start_time": "2024-04-09T18:13:15.173847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 31\n"
     ]
    }
   ],
   "source": [
    "num_features = len(dataset_df.columns) - 1  # Subtract 1 for the target variable\n",
    "print(\"Number of features:\", num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac95dd30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:13:15.208635Z",
     "iopub.status.busy": "2024-04-09T18:13:15.207712Z",
     "iopub.status.idle": "2024-04-09T18:13:15.214660Z",
     "shell.execute_reply": "2024-04-09T18:13:15.213284Z"
    },
    "papermill": {
     "duration": 0.017977,
     "end_time": "2024-04-09T18:13:15.217019",
     "exception": false,
     "start_time": "2024-04-09T18:13:15.199042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. level_group\n",
      "2. event_name_nunique\n",
      "3. name_nunique\n",
      "4. fqid_nunique\n",
      "5. room_fqid_nunique\n",
      "6. text_fqid_nunique\n",
      "7. elapsed_time_mean\n",
      "8. level_mean\n",
      "9. page_mean\n",
      "10. room_coor_x_mean\n",
      "11. room_coor_y_mean\n",
      "12. screen_coor_x_mean\n",
      "13. screen_coor_y_mean\n",
      "14. hover_duration_mean\n",
      "15. elapsed_time_std\n",
      "16. level_std\n",
      "17. page_std\n",
      "18. room_coor_x_std\n",
      "19. room_coor_y_std\n",
      "20. screen_coor_x_std\n",
      "21. screen_coor_y_std\n",
      "22. hover_duration_std\n",
      "23. navigate_click_sum\n",
      "24. person_click_sum\n",
      "25. cutscene_click_sum\n",
      "26. object_click_sum\n",
      "27. map_hover_sum\n",
      "28. notification_click_sum\n",
      "29. map_click_sum\n",
      "30. observation_click_sum\n",
      "31. checkpoint_sum\n"
     ]
    }
   ],
   "source": [
    "# Print feature list with index starting at 1\n",
    "feature_list = dataset_df.columns[:-1]  # Exclude the last column (target variable)\n",
    "for index, feature in enumerate(feature_list, start=1):\n",
    "    print(f\"{index}. {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b5d8930",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:13:15.235169Z",
     "iopub.status.busy": "2024-04-09T18:13:15.234407Z",
     "iopub.status.idle": "2024-04-09T18:13:15.239790Z",
     "shell.execute_reply": "2024-04-09T18:13:15.238627Z"
    },
    "papermill": {
     "duration": 0.017372,
     "end_time": "2024-04-09T18:13:15.242364",
     "exception": false,
     "start_time": "2024-04-09T18:13:15.224992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "FEATURES = [c for c in dataset_df.columns if c != 'level_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e28bcb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:13:15.260511Z",
     "iopub.status.busy": "2024-04-09T18:13:15.260189Z",
     "iopub.status.idle": "2024-04-09T18:13:15.364197Z",
     "shell.execute_reply": "2024-04-09T18:13:15.362809Z"
    },
    "papermill": {
     "duration": 0.116195,
     "end_time": "2024-04-09T18:13:15.366899",
     "exception": false,
     "start_time": "2024-04-09T18:13:15.250704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56547 examples in training, 14139 examples in validation.\n"
     ]
    }
   ],
   "source": [
    "# Splitting DataSet into Train and Valid\n",
    "def split_dataset(dataset, test_ratio=0.20):\n",
    "    USER_LIST = dataset.index.unique()\n",
    "    split = int(len(USER_LIST) * (1 - 0.20))\n",
    "    return dataset.loc[USER_LIST[:split]], dataset.loc[USER_LIST[split:]]\n",
    "\n",
    "# Generating Split DataSet\n",
    "train_x, test_x = split_dataset(dataset_df)\n",
    "print(\"{} examples in training, {} examples in validation.\".format(\n",
    "    len(train_x), len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "137e7daa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:13:15.385839Z",
     "iopub.status.busy": "2024-04-09T18:13:15.384938Z",
     "iopub.status.idle": "2024-04-09T18:13:15.461785Z",
     "shell.execute_reply": "2024-04-09T18:13:15.460333Z"
    },
    "papermill": {
     "duration": 0.089022,
     "end_time": "2024-04-09T18:13:15.464574",
     "exception": false,
     "start_time": "2024-04-09T18:13:15.375552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45237 examples in training, 11310 examples in testing.\n"
     ]
    }
   ],
   "source": [
    "# Splitting the Data into Train and Test\n",
    "train_x, valid_x = split_dataset(train_x)\n",
    "print(\"{} examples in training, {} examples in testing.\".format(\n",
    "    len(train_x), len(valid_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98c5ac46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:13:15.482549Z",
     "iopub.status.busy": "2024-04-09T18:13:15.482195Z",
     "iopub.status.idle": "2024-04-09T18:13:15.492213Z",
     "shell.execute_reply": "2024-04-09T18:13:15.491208Z"
    },
    "papermill": {
     "duration": 0.021489,
     "end_time": "2024-04-09T18:13:15.494641",
     "exception": false,
     "start_time": "2024-04-09T18:13:15.473152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to Split DataSet into Parts\n",
    "def save_to_multiple_csv_files(data, name_prefix, question, header=None, n_parts=5):\n",
    "    # Setting the Directory\n",
    "    # Creating Directory for Each Question\n",
    "    game_prediction_dir = os.path.join(\"/kaggle/working/datasets_\"+str(question), \"student_performance_data\")\n",
    "    os.makedirs(game_prediction_dir, exist_ok=True)\n",
    "    path_format = os.path.join(game_prediction_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6493d2fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:13:15.512196Z",
     "iopub.status.busy": "2024-04-09T18:13:15.511841Z",
     "iopub.status.idle": "2024-04-09T18:13:26.414402Z",
     "shell.execute_reply": "2024-04-09T18:13:26.413423Z"
    },
    "papermill": {
     "duration": 10.914584,
     "end_time": "2024-04-09T18:13:26.417258",
     "exception": false,
     "start_time": "2024-04-09T18:13:15.502674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Generating CSV for q_no 1 grp 0-4\n",
      "##### Generating CSV for q_no 2 grp 0-4\n",
      "##### Generating CSV for q_no 3 grp 0-4\n",
      "##### Generating CSV for q_no 4 grp 5-12\n",
      "##### Generating CSV for q_no 5 grp 5-12\n",
      "##### Generating CSV for q_no 6 grp 5-12\n",
      "##### Generating CSV for q_no 7 grp 5-12\n",
      "##### Generating CSV for q_no 8 grp 5-12\n",
      "##### Generating CSV for q_no 9 grp 5-12\n",
      "##### Generating CSV for q_no 10 grp 5-12\n",
      "##### Generating CSV for q_no 11 grp 5-12\n",
      "##### Generating CSV for q_no 12 grp 5-12\n",
      "##### Generating CSV for q_no 13 grp 5-12\n",
      "##### Generating CSV for q_no 14 grp 13-22\n",
      "##### Generating CSV for q_no 15 grp 13-22\n",
      "##### Generating CSV for q_no 16 grp 13-22\n",
      "##### Generating CSV for q_no 17 grp 13-22\n",
      "##### Generating CSV for q_no 18 grp 13-22\n"
     ]
    }
   ],
   "source": [
    "# Generating CSV files for Each Question and Saving them\n",
    "train_file_paths_for_questions = []\n",
    "valid_file_paths_for_questions = []\n",
    "test_file_paths_for_questions = []\n",
    "\n",
    "header_cols = train_x.columns\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "for q_no in range(1,19):\n",
    "    \n",
    "    # Selecting the Group based on Question Number\n",
    "    if q_no<=3: grp = '0-4'\n",
    "    elif q_no<=13: grp = '5-12'\n",
    "    elif q_no<=22: grp = '13-22'\n",
    "    print(\"##### Generating CSV for q_no\", q_no, \"grp\", grp)\n",
    "    \n",
    "    # Filter the rows in the datasets based on the selected level group. \n",
    "    train_df = train_x.loc[train_x.level_group == grp]\n",
    "    train_users = train_df.index.values\n",
    "    valid_df = valid_x.loc[valid_x.level_group == grp]\n",
    "    valid_users = valid_df.index.values\n",
    "    test_df = test_x.loc[test_x.level_group == grp]\n",
    "    test_users = test_df.index.values\n",
    "    \n",
    "    # Select the labels for the related q_no.\n",
    "    train_labels = labels.loc[labels.q==q_no].set_index('session').loc[train_users]\n",
    "    valid_labels = labels.loc[labels.q==q_no].set_index('session').loc[valid_users]\n",
    "    test_labels = labels.loc[labels.q==q_no].set_index('session').loc[test_users]\n",
    "    \n",
    "     # Add the label to the filtered datasets.\n",
    "    train_df[\"correct\"] = train_labels[\"correct\"]\n",
    "    valid_df[\"correct\"] = valid_labels[\"correct\"]\n",
    "    test_df[\"correct\"] = test_labels[\"correct\"]\n",
    "    \n",
    "    # Dropping Column Level Group\n",
    "    train_ds_data = train_df.drop(columns=['level_group'])\n",
    "    valid_ds_data = valid_df.drop(columns=['level_group'])\n",
    "    test_ds_data = test_df.drop(columns=['level_group'])\n",
    "    train_ds_data.reset_index()\n",
    "    valid_ds_data.reset_index()\n",
    "    test_ds_data.reset_index()\n",
    "    \n",
    "    # Calling function to generate CSVs\n",
    "    train_filepaths = save_to_multiple_csv_files(train_ds_data.to_numpy(), \"train\", \"q_no_\"+str(q_no), header, n_parts=5)\n",
    "    valid_filepaths = save_to_multiple_csv_files(valid_ds_data.to_numpy(), \"valid\", \"q_no_\"+str(q_no), header, n_parts=5)\n",
    "    test_filepaths = save_to_multiple_csv_files(test_ds_data.to_numpy(), \"test\", \"q_no_\"+str(q_no), header, n_parts=5)\n",
    "    \n",
    "    # Saving File Paths\n",
    "    train_file_paths_for_questions.append(train_filepaths)\n",
    "    valid_file_paths_for_questions.append(valid_filepaths)\n",
    "    test_file_paths_for_questions.append(test_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf9a78ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:13:26.437099Z",
     "iopub.status.busy": "2024-04-09T18:13:26.436409Z",
     "iopub.status.idle": "2024-04-09T18:13:26.443268Z",
     "shell.execute_reply": "2024-04-09T18:13:26.442186Z"
    },
    "papermill": {
     "duration": 0.019314,
     "end_time": "2024-04-09T18:13:26.445597",
     "exception": false,
     "start_time": "2024-04-09T18:13:26.426283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pre Process Function\n",
    "n_inputs = 31\n",
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    X = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6239148a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:13:26.466334Z",
     "iopub.status.busy": "2024-04-09T18:13:26.465268Z",
     "iopub.status.idle": "2024-04-09T18:13:26.473351Z",
     "shell.execute_reply": "2024-04-09T18:13:26.472434Z"
    },
    "papermill": {
     "duration": 0.020679,
     "end_time": "2024-04-09T18:13:26.475638",
     "exception": false,
     "start_time": "2024-04-09T18:13:26.454959",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CSV Reader for Train\n",
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,  # number of files or filepaths\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    \n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1), # skip the header row via map_func\n",
    "        cycle_length=n_readers, # 'interleave' pull cycle_length(=n_readers) file paths(1 by 1) from the 'dataset'\n",
    "        num_parallel_calls=n_read_threads) \n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab8ff09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:13:26.495492Z",
     "iopub.status.busy": "2024-04-09T18:13:26.494884Z",
     "iopub.status.idle": "2024-04-09T18:13:33.568914Z",
     "shell.execute_reply": "2024-04-09T18:13:33.567941Z"
    },
    "papermill": {
     "duration": 7.086818,
     "end_time": "2024-04-09T18:13:33.571694",
     "exception": false,
     "start_time": "2024-04-09T18:13:26.484876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Loading CSV for q_no 1 grp 0-4\n",
      "##### Loading CSV for q_no 2 grp 0-4\n",
      "##### Loading CSV for q_no 3 grp 0-4\n",
      "##### Loading CSV for q_no 4 grp 5-12\n",
      "##### Loading CSV for q_no 5 grp 5-12\n",
      "##### Loading CSV for q_no 6 grp 5-12\n",
      "##### Loading CSV for q_no 7 grp 5-12\n",
      "##### Loading CSV for q_no 8 grp 5-12\n",
      "##### Loading CSV for q_no 9 grp 5-12\n",
      "##### Loading CSV for q_no 10 grp 5-12\n",
      "##### Loading CSV for q_no 11 grp 5-12\n",
      "##### Loading CSV for q_no 12 grp 5-12\n",
      "##### Loading CSV for q_no 13 grp 5-12\n",
      "##### Loading CSV for q_no 14 grp 13-22\n",
      "##### Loading CSV for q_no 15 grp 13-22\n",
      "##### Loading CSV for q_no 16 grp 13-22\n",
      "##### Loading CSV for q_no 17 grp 13-22\n",
      "##### Loading CSV for q_no 18 grp 13-22\n"
     ]
    }
   ],
   "source": [
    "# Using the Saved CSV Loading the Data and saving them to a List\n",
    "train_set_list = []\n",
    "valid_set_list = []\n",
    "test_set_list = []\n",
    "\n",
    "for q_no in range(1,19):\n",
    "\n",
    "    # Select level group for the question based on the q_no.\n",
    "    if q_no<=3: grp = '0-4'\n",
    "    elif q_no<=13: grp = '5-12'\n",
    "    elif q_no<=22: grp = '13-22'\n",
    "    print(\"##### Loading CSV for q_no\", q_no, \"grp\", grp)\n",
    "    \n",
    "    train_set = csv_reader_dataset(train_file_paths_for_questions[q_no - 1])\n",
    "    valid_set = csv_reader_dataset(valid_file_paths_for_questions[q_no - 1]) \n",
    "    test_set = csv_reader_dataset(test_file_paths_for_questions[q_no - 1])   \n",
    "    \n",
    "    train_set_list.append(train_set)\n",
    "    valid_set_list.append(valid_set)\n",
    "    test_set_list.append(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20be08ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:13:33.594402Z",
     "iopub.status.busy": "2024-04-09T18:13:33.593801Z",
     "iopub.status.idle": "2024-04-09T18:34:58.439225Z",
     "shell.execute_reply": "2024-04-09T18:34:58.437861Z"
    },
    "papermill": {
     "duration": 1284.859927,
     "end_time": "2024-04-09T18:34:58.442192",
     "exception": false,
     "start_time": "2024-04-09T18:13:33.582265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Training for q_no 1 grp 0-4\n",
      "Training fold 1 for question number 1\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 18s 150ms/step - loss: 0.5250 - accuracy: 0.8456 - val_loss: 0.5630 - val_accuracy: 0.9088\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4011 - accuracy: 0.9019 - val_loss: 0.4738 - val_accuracy: 0.9188\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3582 - accuracy: 0.9073 - val_loss: 0.4050 - val_accuracy: 0.9188\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3279 - accuracy: 0.9083 - val_loss: 0.3611 - val_accuracy: 0.9153\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3024 - accuracy: 0.9084 - val_loss: 0.3277 - val_accuracy: 0.9102\n",
      "Training fold 2 for question number 1\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 141ms/step - loss: 0.4477 - accuracy: 0.8942 - val_loss: 0.5750 - val_accuracy: 0.8966\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3899 - accuracy: 0.9104 - val_loss: 0.5046 - val_accuracy: 0.9066\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3522 - accuracy: 0.9125 - val_loss: 0.4502 - val_accuracy: 0.9024\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3223 - accuracy: 0.9129 - val_loss: 0.4005 - val_accuracy: 0.8952\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2983 - accuracy: 0.9121 - val_loss: 0.3597 - val_accuracy: 0.8921\n",
      "Training fold 3 for question number 1\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 141ms/step - loss: 0.4655 - accuracy: 0.8892 - val_loss: 0.5681 - val_accuracy: 0.8726\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3930 - accuracy: 0.9092 - val_loss: 0.4967 - val_accuracy: 0.9126\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3564 - accuracy: 0.9111 - val_loss: 0.4355 - val_accuracy: 0.9126\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3282 - accuracy: 0.9109 - val_loss: 0.3890 - val_accuracy: 0.9084\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3027 - accuracy: 0.9111 - val_loss: 0.3519 - val_accuracy: 0.9031\n",
      "Training fold 4 for question number 1\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 141ms/step - loss: 0.4706 - accuracy: 0.8856 - val_loss: 0.5764 - val_accuracy: 0.9008\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.3912 - accuracy: 0.9088 - val_loss: 0.5146 - val_accuracy: 0.9108\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3514 - accuracy: 0.9111 - val_loss: 0.4632 - val_accuracy: 0.8872\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.3225 - accuracy: 0.9103 - val_loss: 0.4140 - val_accuracy: 0.8748\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.2988 - accuracy: 0.9093 - val_loss: 0.3813 - val_accuracy: 0.7867\n",
      "Training fold 5 for question number 1\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 138ms/step - loss: 0.4575 - accuracy: 0.8884 - val_loss: 0.5989 - val_accuracy: 0.8342\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3919 - accuracy: 0.9099 - val_loss: 0.5274 - val_accuracy: 0.8931\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3567 - accuracy: 0.9114 - val_loss: 0.4625 - val_accuracy: 0.9140\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3279 - accuracy: 0.9105 - val_loss: 0.4162 - val_accuracy: 0.9095\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3054 - accuracy: 0.9093 - val_loss: 0.3722 - val_accuracy: 0.9008\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2856 - accuracy: 0.9092 - val_loss: 0.3450 - val_accuracy: 0.8811\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4621 - accuracy: 0.9147\n",
      "5/5 [==============================] - 2s 12ms/step\n",
      "##### Training for q_no 2 grp 0-4\n",
      "Training fold 1 for question number 2\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 143ms/step - loss: 0.0944 - accuracy: 0.9875 - val_loss: 0.4095 - val_accuracy: 0.9441\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0689 - accuracy: 0.9933 - val_loss: 0.3269 - val_accuracy: 0.9542\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0654 - accuracy: 0.9933 - val_loss: 0.2564 - val_accuracy: 0.9742\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0630 - accuracy: 0.9933 - val_loss: 0.1960 - val_accuracy: 0.9842\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0596 - accuracy: 0.9933 - val_loss: 0.1470 - val_accuracy: 0.9942\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0573 - accuracy: 0.9933 - val_loss: 0.1131 - val_accuracy: 0.9942\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0541 - accuracy: 0.9933 - val_loss: 0.0917 - val_accuracy: 0.9942\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0518 - accuracy: 0.9933 - val_loss: 0.0736 - val_accuracy: 0.9942\n",
      "Training fold 2 for question number 2\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 11s 141ms/step - loss: 0.1061 - accuracy: 0.9828 - val_loss: 0.4111 - val_accuracy: 0.9325\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0668 - accuracy: 0.9937 - val_loss: 0.3291 - val_accuracy: 0.9525\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0628 - accuracy: 0.9937 - val_loss: 0.2581 - val_accuracy: 0.9625\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0604 - accuracy: 0.9937 - val_loss: 0.2003 - val_accuracy: 0.9725\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0582 - accuracy: 0.9937 - val_loss: 0.1551 - val_accuracy: 0.9825\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0550 - accuracy: 0.9937 - val_loss: 0.1230 - val_accuracy: 0.9925\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0529 - accuracy: 0.9937 - val_loss: 0.0975 - val_accuracy: 0.9925\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0505 - accuracy: 0.9937 - val_loss: 0.0807 - val_accuracy: 0.9925\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0480 - accuracy: 0.9937 - val_loss: 0.0693 - val_accuracy: 0.9925\n",
      "Training fold 3 for question number 2\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 139ms/step - loss: 0.1766 - accuracy: 0.9327 - val_loss: 0.3857 - val_accuracy: 0.9542\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0721 - accuracy: 0.9933 - val_loss: 0.3036 - val_accuracy: 0.9642\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0676 - accuracy: 0.9933 - val_loss: 0.2464 - val_accuracy: 0.9742\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0655 - accuracy: 0.9933 - val_loss: 0.2033 - val_accuracy: 0.9842\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0630 - accuracy: 0.9933 - val_loss: 0.1658 - val_accuracy: 0.9842\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0607 - accuracy: 0.9933 - val_loss: 0.1348 - val_accuracy: 0.9942\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0578 - accuracy: 0.9933 - val_loss: 0.1114 - val_accuracy: 0.9942\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0563 - accuracy: 0.9933 - val_loss: 0.0925 - val_accuracy: 0.9942\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.0541 - accuracy: 0.9933 - val_loss: 0.0773 - val_accuracy: 0.9942\n",
      "Training fold 4 for question number 2\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 144ms/step - loss: 0.2417 - accuracy: 0.9046 - val_loss: 0.4315 - val_accuracy: 0.9131\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.0677 - accuracy: 0.9936 - val_loss: 0.3336 - val_accuracy: 0.9331\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0654 - accuracy: 0.9936 - val_loss: 0.2673 - val_accuracy: 0.9531\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0631 - accuracy: 0.9936 - val_loss: 0.2124 - val_accuracy: 0.9631\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0610 - accuracy: 0.9936 - val_loss: 0.1665 - val_accuracy: 0.9731\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0599 - accuracy: 0.9936 - val_loss: 0.1276 - val_accuracy: 0.9831\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0570 - accuracy: 0.9936 - val_loss: 0.1032 - val_accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0557 - accuracy: 0.9936 - val_loss: 0.0852 - val_accuracy: 0.9931\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0540 - accuracy: 0.9936 - val_loss: 0.0729 - val_accuracy: 0.9931\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0513 - accuracy: 0.9936 - val_loss: 0.0648 - val_accuracy: 0.9931\n",
      "Training fold 5 for question number 2\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 11s 138ms/step - loss: 0.1489 - accuracy: 0.9616 - val_loss: 0.4421 - val_accuracy: 0.9036\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0670 - accuracy: 0.9935 - val_loss: 0.3424 - val_accuracy: 0.9436\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0647 - accuracy: 0.9935 - val_loss: 0.2730 - val_accuracy: 0.9536\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0626 - accuracy: 0.9935 - val_loss: 0.2144 - val_accuracy: 0.9735\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0604 - accuracy: 0.9935 - val_loss: 0.1670 - val_accuracy: 0.9835\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.0573 - accuracy: 0.9935 - val_loss: 0.1352 - val_accuracy: 0.9836\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0551 - accuracy: 0.9935 - val_loss: 0.1087 - val_accuracy: 0.9935\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0532 - accuracy: 0.9935 - val_loss: 0.0884 - val_accuracy: 0.9935\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0508 - accuracy: 0.9935 - val_loss: 0.0733 - val_accuracy: 0.9935\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.0493 - accuracy: 0.9935 - val_loss: 0.0618 - val_accuracy: 0.9935\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.1130 - accuracy: 0.9922\n",
      "5/5 [==============================] - 2s 12ms/step\n",
      "##### Training for q_no 3 grp 0-4\n",
      "Training fold 1 for question number 3\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 140ms/step - loss: 0.2359 - accuracy: 0.9391 - val_loss: 0.4764 - val_accuracy: 0.8991\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1640 - accuracy: 0.9787 - val_loss: 0.3976 - val_accuracy: 0.9291\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1509 - accuracy: 0.9787 - val_loss: 0.3278 - val_accuracy: 0.9491\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1401 - accuracy: 0.9787 - val_loss: 0.2708 - val_accuracy: 0.9691\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1300 - accuracy: 0.9788 - val_loss: 0.2274 - val_accuracy: 0.9791\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1225 - accuracy: 0.9788 - val_loss: 0.1961 - val_accuracy: 0.9791\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1157 - accuracy: 0.9787 - val_loss: 0.1713 - val_accuracy: 0.9791\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1091 - accuracy: 0.9788 - val_loss: 0.1564 - val_accuracy: 0.9791\n",
      "Training fold 2 for question number 3\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 141ms/step - loss: 0.2527 - accuracy: 0.9351 - val_loss: 0.4776 - val_accuracy: 0.8984\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1661 - accuracy: 0.9789 - val_loss: 0.4009 - val_accuracy: 0.9384\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1507 - accuracy: 0.9789 - val_loss: 0.3256 - val_accuracy: 0.9584\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1398 - accuracy: 0.9789 - val_loss: 0.2737 - val_accuracy: 0.9685\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1310 - accuracy: 0.9789 - val_loss: 0.2281 - val_accuracy: 0.9784\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1211 - accuracy: 0.9789 - val_loss: 0.2003 - val_accuracy: 0.9784\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1151 - accuracy: 0.9789 - val_loss: 0.1744 - val_accuracy: 0.9784\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1084 - accuracy: 0.9789 - val_loss: 0.1628 - val_accuracy: 0.9784\n",
      "Training fold 3 for question number 3\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 11s 140ms/step - loss: 0.2460 - accuracy: 0.9433 - val_loss: 0.4723 - val_accuracy: 0.9393\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1651 - accuracy: 0.9787 - val_loss: 0.3984 - val_accuracy: 0.9493\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1507 - accuracy: 0.9787 - val_loss: 0.3239 - val_accuracy: 0.9693\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1408 - accuracy: 0.9787 - val_loss: 0.2697 - val_accuracy: 0.9793\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1296 - accuracy: 0.9787 - val_loss: 0.2259 - val_accuracy: 0.9793\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1223 - accuracy: 0.9787 - val_loss: 0.1937 - val_accuracy: 0.9793\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1157 - accuracy: 0.9787 - val_loss: 0.1695 - val_accuracy: 0.9793\n",
      "Training fold 4 for question number 3\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 141ms/step - loss: 0.2981 - accuracy: 0.9355 - val_loss: 0.4417 - val_accuracy: 0.9488\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1700 - accuracy: 0.9788 - val_loss: 0.3676 - val_accuracy: 0.9588\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1519 - accuracy: 0.9787 - val_loss: 0.3072 - val_accuracy: 0.9688\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1396 - accuracy: 0.9788 - val_loss: 0.2578 - val_accuracy: 0.9788\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1303 - accuracy: 0.9788 - val_loss: 0.2183 - val_accuracy: 0.9788\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1214 - accuracy: 0.9789 - val_loss: 0.1907 - val_accuracy: 0.9788\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1162 - accuracy: 0.9788 - val_loss: 0.1658 - val_accuracy: 0.9788\n",
      "Training fold 5 for question number 3\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 145ms/step - loss: 0.2310 - accuracy: 0.9431 - val_loss: 0.4709 - val_accuracy: 0.9386\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1630 - accuracy: 0.9789 - val_loss: 0.3968 - val_accuracy: 0.9486\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1506 - accuracy: 0.9789 - val_loss: 0.3264 - val_accuracy: 0.9586\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1397 - accuracy: 0.9789 - val_loss: 0.2758 - val_accuracy: 0.9686\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1302 - accuracy: 0.9789 - val_loss: 0.2338 - val_accuracy: 0.9786\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1233 - accuracy: 0.9789 - val_loss: 0.1982 - val_accuracy: 0.9786\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1166 - accuracy: 0.9789 - val_loss: 0.1725 - val_accuracy: 0.9786\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1106 - accuracy: 0.9789 - val_loss: 0.1547 - val_accuracy: 0.9786\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2321 - accuracy: 0.9793\n",
      "5/5 [==============================] - 1s 9ms/step\n",
      "##### Training for q_no 4 grp 5-12\n",
      "Training fold 1 for question number 4\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 11s 140ms/step - loss: 0.4599 - accuracy: 0.8632 - val_loss: 0.5448 - val_accuracy: 0.8853\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3305 - accuracy: 0.9336 - val_loss: 0.4581 - val_accuracy: 0.9153\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3010 - accuracy: 0.9360 - val_loss: 0.3913 - val_accuracy: 0.9351\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2754 - accuracy: 0.9359 - val_loss: 0.3374 - val_accuracy: 0.9351\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2559 - accuracy: 0.9359 - val_loss: 0.2995 - val_accuracy: 0.9288\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2418 - accuracy: 0.9356 - val_loss: 0.2729 - val_accuracy: 0.9288\n",
      "Training fold 2 for question number 4\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 146ms/step - loss: 0.3862 - accuracy: 0.9206 - val_loss: 0.5643 - val_accuracy: 0.9071\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3284 - accuracy: 0.9346 - val_loss: 0.4937 - val_accuracy: 0.9271\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2963 - accuracy: 0.9353 - val_loss: 0.4361 - val_accuracy: 0.9371\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2728 - accuracy: 0.9351 - val_loss: 0.3896 - val_accuracy: 0.9371\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2548 - accuracy: 0.9345 - val_loss: 0.3438 - val_accuracy: 0.9305\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2376 - accuracy: 0.9342 - val_loss: 0.3210 - val_accuracy: 0.9195\n",
      "Training fold 3 for question number 4\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 142ms/step - loss: 0.4966 - accuracy: 0.8461 - val_loss: 0.5396 - val_accuracy: 0.9254\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3328 - accuracy: 0.9306 - val_loss: 0.4604 - val_accuracy: 0.9354\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3021 - accuracy: 0.9350 - val_loss: 0.4070 - val_accuracy: 0.9354\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.2747 - accuracy: 0.9356 - val_loss: 0.3562 - val_accuracy: 0.9290\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2574 - accuracy: 0.9355 - val_loss: 0.3216 - val_accuracy: 0.9290\n",
      "Training fold 4 for question number 4\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 144ms/step - loss: 0.4494 - accuracy: 0.8736 - val_loss: 0.5490 - val_accuracy: 0.8854\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3318 - accuracy: 0.9332 - val_loss: 0.4741 - val_accuracy: 0.9054\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3009 - accuracy: 0.9357 - val_loss: 0.4130 - val_accuracy: 0.9254\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2772 - accuracy: 0.9358 - val_loss: 0.3601 - val_accuracy: 0.9354\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2574 - accuracy: 0.9360 - val_loss: 0.3271 - val_accuracy: 0.9354\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2417 - accuracy: 0.9356 - val_loss: 0.2983 - val_accuracy: 0.9354\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2289 - accuracy: 0.9357 - val_loss: 0.2765 - val_accuracy: 0.9242\n",
      "Training fold 5 for question number 4\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 144ms/step - loss: 0.4401 - accuracy: 0.8803 - val_loss: 0.5656 - val_accuracy: 0.9173\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3313 - accuracy: 0.9325 - val_loss: 0.4852 - val_accuracy: 0.9273\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2996 - accuracy: 0.9343 - val_loss: 0.4233 - val_accuracy: 0.9371\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2741 - accuracy: 0.9351 - val_loss: 0.3819 - val_accuracy: 0.9309\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2543 - accuracy: 0.9349 - val_loss: 0.3478 - val_accuracy: 0.9182\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2388 - accuracy: 0.9350 - val_loss: 0.3295 - val_accuracy: 0.8883\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4249 - accuracy: 0.9337\n",
      "5/5 [==============================] - 2s 8ms/step\n",
      "##### Training for q_no 5 grp 5-12\n",
      "Training fold 1 for question number 5\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 141ms/step - loss: 0.6063 - accuracy: 0.7851 - val_loss: 0.6200 - val_accuracy: 0.8580\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5092 - accuracy: 0.8325 - val_loss: 0.5516 - val_accuracy: 0.8569\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4577 - accuracy: 0.8426 - val_loss: 0.4931 - val_accuracy: 0.8569\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4177 - accuracy: 0.8473 - val_loss: 0.4462 - val_accuracy: 0.8450\n",
      "Training fold 2 for question number 5\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 141ms/step - loss: 0.6088 - accuracy: 0.7830 - val_loss: 0.6201 - val_accuracy: 0.8147\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5104 - accuracy: 0.8330 - val_loss: 0.5513 - val_accuracy: 0.8546\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4598 - accuracy: 0.8440 - val_loss: 0.4956 - val_accuracy: 0.8383\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4180 - accuracy: 0.8495 - val_loss: 0.4520 - val_accuracy: 0.8246\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3822 - accuracy: 0.8500 - val_loss: 0.4148 - val_accuracy: 0.8246\n",
      "Training fold 3 for question number 5\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 141ms/step - loss: 0.6036 - accuracy: 0.7932 - val_loss: 0.6195 - val_accuracy: 0.8253\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5066 - accuracy: 0.8350 - val_loss: 0.5477 - val_accuracy: 0.8521\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4549 - accuracy: 0.8456 - val_loss: 0.4921 - val_accuracy: 0.8247\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4137 - accuracy: 0.8495 - val_loss: 0.4471 - val_accuracy: 0.8247\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3787 - accuracy: 0.8512 - val_loss: 0.4120 - val_accuracy: 0.8247\n",
      "Training fold 4 for question number 5\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 146ms/step - loss: 0.5804 - accuracy: 0.8019 - val_loss: 0.6168 - val_accuracy: 0.8518\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.5054 - accuracy: 0.8318 - val_loss: 0.5485 - val_accuracy: 0.8514\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4527 - accuracy: 0.8450 - val_loss: 0.4881 - val_accuracy: 0.8504\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4100 - accuracy: 0.8494 - val_loss: 0.4428 - val_accuracy: 0.8269\n",
      "Training fold 5 for question number 5\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 140ms/step - loss: 0.5865 - accuracy: 0.8097 - val_loss: 0.6172 - val_accuracy: 0.8530\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5050 - accuracy: 0.8397 - val_loss: 0.5486 - val_accuracy: 0.8508\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.4546 - accuracy: 0.8493 - val_loss: 0.4915 - val_accuracy: 0.8486\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4164 - accuracy: 0.8508 - val_loss: 0.4421 - val_accuracy: 0.8291\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.6155 - accuracy: 0.8584\n",
      "5/5 [==============================] - 2s 7ms/step\n",
      "##### Training for q_no 6 grp 5-12\n",
      "Training fold 1 for question number 6\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 12s 140ms/step - loss: 0.4476 - accuracy: 0.8812 - val_loss: 0.5581 - val_accuracy: 0.9272\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3517 - accuracy: 0.9242 - val_loss: 0.4852 - val_accuracy: 0.9272\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.3184 - accuracy: 0.9263 - val_loss: 0.4266 - val_accuracy: 0.9218\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2906 - accuracy: 0.9264 - val_loss: 0.3860 - val_accuracy: 0.9155\n",
      "Training fold 2 for question number 6\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 143ms/step - loss: 0.4528 - accuracy: 0.8866 - val_loss: 0.5593 - val_accuracy: 0.8998\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3576 - accuracy: 0.9216 - val_loss: 0.4817 - val_accuracy: 0.9197\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3225 - accuracy: 0.9253 - val_loss: 0.4249 - val_accuracy: 0.9297\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2974 - accuracy: 0.9262 - val_loss: 0.3753 - val_accuracy: 0.9297\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2766 - accuracy: 0.9258 - val_loss: 0.3316 - val_accuracy: 0.9230\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2582 - accuracy: 0.9258 - val_loss: 0.3064 - val_accuracy: 0.9182\n",
      "Training fold 3 for question number 6\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 11s 148ms/step - loss: 0.4505 - accuracy: 0.8885 - val_loss: 0.5605 - val_accuracy: 0.8979\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3565 - accuracy: 0.9233 - val_loss: 0.4807 - val_accuracy: 0.9279\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3198 - accuracy: 0.9261 - val_loss: 0.4179 - val_accuracy: 0.9279\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2928 - accuracy: 0.9268 - val_loss: 0.3723 - val_accuracy: 0.9279\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2716 - accuracy: 0.9259 - val_loss: 0.3357 - val_accuracy: 0.9225\n",
      "Training fold 4 for question number 6\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 11s 154ms/step - loss: 0.4337 - accuracy: 0.9035 - val_loss: 0.5766 - val_accuracy: 0.8353\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.3554 - accuracy: 0.9233 - val_loss: 0.4853 - val_accuracy: 0.8953\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3210 - accuracy: 0.9270 - val_loss: 0.4145 - val_accuracy: 0.9253\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2946 - accuracy: 0.9274 - val_loss: 0.3582 - val_accuracy: 0.9253\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2719 - accuracy: 0.9274 - val_loss: 0.3231 - val_accuracy: 0.9253\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2549 - accuracy: 0.9271 - val_loss: 0.2939 - val_accuracy: 0.9204\n",
      "Training fold 5 for question number 6\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 11s 154ms/step - loss: 0.4781 - accuracy: 0.8726 - val_loss: 0.5652 - val_accuracy: 0.8874\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.3571 - accuracy: 0.9210 - val_loss: 0.4787 - val_accuracy: 0.9275\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3240 - accuracy: 0.9254 - val_loss: 0.4102 - val_accuracy: 0.9275\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2957 - accuracy: 0.9269 - val_loss: 0.3623 - val_accuracy: 0.9275\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.2738 - accuracy: 0.9268 - val_loss: 0.3276 - val_accuracy: 0.9164\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4740 - accuracy: 0.9322\n",
      "5/5 [==============================] - 2s 12ms/step\n",
      "##### Training for q_no 7 grp 5-12\n",
      "Training fold 1 for question number 7\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 11s 149ms/step - loss: 0.4818 - accuracy: 0.8725 - val_loss: 0.5690 - val_accuracy: 0.8933\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.3875 - accuracy: 0.9099 - val_loss: 0.5018 - val_accuracy: 0.9133\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.3517 - accuracy: 0.9134 - val_loss: 0.4432 - val_accuracy: 0.9133\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3214 - accuracy: 0.9140 - val_loss: 0.3966 - val_accuracy: 0.9058\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2985 - accuracy: 0.9139 - val_loss: 0.3577 - val_accuracy: 0.8997\n",
      "Training fold 2 for question number 7\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 13s 154ms/step - loss: 0.5230 - accuracy: 0.8374 - val_loss: 0.5832 - val_accuracy: 0.8655\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.3946 - accuracy: 0.9086 - val_loss: 0.5053 - val_accuracy: 0.8955\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.3586 - accuracy: 0.9137 - val_loss: 0.4444 - val_accuracy: 0.9155\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3301 - accuracy: 0.9139 - val_loss: 0.3926 - val_accuracy: 0.9155\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3078 - accuracy: 0.9137 - val_loss: 0.3531 - val_accuracy: 0.9155\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2882 - accuracy: 0.9137 - val_loss: 0.3232 - val_accuracy: 0.9067\n",
      "Training fold 3 for question number 7\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 11s 151ms/step - loss: 0.5374 - accuracy: 0.8335 - val_loss: 0.5862 - val_accuracy: 0.8558\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.3928 - accuracy: 0.9077 - val_loss: 0.5190 - val_accuracy: 0.8758\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3559 - accuracy: 0.9136 - val_loss: 0.4575 - val_accuracy: 0.9058\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.3265 - accuracy: 0.9137 - val_loss: 0.4084 - val_accuracy: 0.9158\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3044 - accuracy: 0.9134 - val_loss: 0.3704 - val_accuracy: 0.9158\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2844 - accuracy: 0.9133 - val_loss: 0.3351 - val_accuracy: 0.9158\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.2688 - accuracy: 0.9131 - val_loss: 0.3129 - val_accuracy: 0.9107\n",
      "Training fold 4 for question number 7\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 11s 156ms/step - loss: 0.4564 - accuracy: 0.8904 - val_loss: 0.5827 - val_accuracy: 0.8634\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.3868 - accuracy: 0.9123 - val_loss: 0.5073 - val_accuracy: 0.9134\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.3500 - accuracy: 0.9139 - val_loss: 0.4435 - val_accuracy: 0.9134\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3242 - accuracy: 0.9141 - val_loss: 0.3950 - val_accuracy: 0.9080\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3018 - accuracy: 0.9138 - val_loss: 0.3574 - val_accuracy: 0.8983\n",
      "Training fold 5 for question number 7\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 11s 146ms/step - loss: 0.4640 - accuracy: 0.8860 - val_loss: 0.5790 - val_accuracy: 0.8665\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3880 - accuracy: 0.9100 - val_loss: 0.4991 - val_accuracy: 0.9064\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3518 - accuracy: 0.9128 - val_loss: 0.4430 - val_accuracy: 0.9164\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3218 - accuracy: 0.9133 - val_loss: 0.3937 - val_accuracy: 0.9164\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2978 - accuracy: 0.9126 - val_loss: 0.3542 - val_accuracy: 0.9119\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2778 - accuracy: 0.9125 - val_loss: 0.3282 - val_accuracy: 0.8908\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4419 - accuracy: 0.9191\n",
      "5/5 [==============================] - 2s 12ms/step\n",
      "##### Training for q_no 8 grp 5-12\n",
      "Training fold 1 for question number 8\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 145ms/step - loss: 0.5398 - accuracy: 0.8447 - val_loss: 0.6067 - val_accuracy: 0.8674\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.4695 - accuracy: 0.8683 - val_loss: 0.5474 - val_accuracy: 0.8735\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4218 - accuracy: 0.8720 - val_loss: 0.4935 - val_accuracy: 0.8026\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3855 - accuracy: 0.8731 - val_loss: 0.4524 - val_accuracy: 0.8026\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3570 - accuracy: 0.8705 - val_loss: 0.4117 - val_accuracy: 0.8026\n",
      "Training fold 2 for question number 8\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 152ms/step - loss: 0.5468 - accuracy: 0.8370 - val_loss: 0.6153 - val_accuracy: 0.8348\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.4710 - accuracy: 0.8631 - val_loss: 0.5491 - val_accuracy: 0.8748\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4211 - accuracy: 0.8715 - val_loss: 0.4917 - val_accuracy: 0.8664\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3865 - accuracy: 0.8733 - val_loss: 0.4447 - val_accuracy: 0.8120\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3537 - accuracy: 0.8726 - val_loss: 0.3978 - val_accuracy: 0.8057\n",
      "Training fold 3 for question number 8\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 146ms/step - loss: 0.5542 - accuracy: 0.8265 - val_loss: 0.5859 - val_accuracy: 0.8684\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4727 - accuracy: 0.8658 - val_loss: 0.5169 - val_accuracy: 0.8764\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4240 - accuracy: 0.8711 - val_loss: 0.4655 - val_accuracy: 0.8591\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3871 - accuracy: 0.8714 - val_loss: 0.4291 - val_accuracy: 0.8016\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3578 - accuracy: 0.8712 - val_loss: 0.3937 - val_accuracy: 0.8016\n",
      "Training fold 4 for question number 8\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 13s 327ms/step - loss: 0.5413 - accuracy: 0.8388 - val_loss: 0.6033 - val_accuracy: 0.8774\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.4685 - accuracy: 0.8628 - val_loss: 0.5341 - val_accuracy: 0.8774\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4211 - accuracy: 0.8698 - val_loss: 0.4743 - val_accuracy: 0.8728\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.3832 - accuracy: 0.8714 - val_loss: 0.4200 - val_accuracy: 0.8574\n",
      "Training fold 5 for question number 8\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 144ms/step - loss: 0.5704 - accuracy: 0.8121 - val_loss: 0.6235 - val_accuracy: 0.8145\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4729 - accuracy: 0.8666 - val_loss: 0.5413 - val_accuracy: 0.8643\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4273 - accuracy: 0.8719 - val_loss: 0.4676 - val_accuracy: 0.8742\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3900 - accuracy: 0.8743 - val_loss: 0.4130 - val_accuracy: 0.8725\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3588 - accuracy: 0.8739 - val_loss: 0.3668 - val_accuracy: 0.8710\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3361 - accuracy: 0.8721 - val_loss: 0.3309 - val_accuracy: 0.8675\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4633 - accuracy: 0.8832\n",
      "5/5 [==============================] - 2s 9ms/step\n",
      "##### Training for q_no 9 grp 5-12\n",
      "Training fold 1 for question number 9\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 149ms/step - loss: 0.4988 - accuracy: 0.8637 - val_loss: 0.5659 - val_accuracy: 0.8882\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3887 - accuracy: 0.9058 - val_loss: 0.4880 - val_accuracy: 0.9082\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3491 - accuracy: 0.9128 - val_loss: 0.4292 - val_accuracy: 0.9082\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3177 - accuracy: 0.9143 - val_loss: 0.3870 - val_accuracy: 0.9036\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2956 - accuracy: 0.9141 - val_loss: 0.3533 - val_accuracy: 0.8913\n",
      "Training fold 2 for question number 9\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 143ms/step - loss: 0.4643 - accuracy: 0.8839 - val_loss: 0.5831 - val_accuracy: 0.8250\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3884 - accuracy: 0.9099 - val_loss: 0.4866 - val_accuracy: 0.8849\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3484 - accuracy: 0.9122 - val_loss: 0.4214 - val_accuracy: 0.9149\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3230 - accuracy: 0.9117 - val_loss: 0.3740 - val_accuracy: 0.9107\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2983 - accuracy: 0.9107 - val_loss: 0.3358 - val_accuracy: 0.9059\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2793 - accuracy: 0.9109 - val_loss: 0.3073 - val_accuracy: 0.9008\n",
      "Training fold 3 for question number 9\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 147ms/step - loss: 0.4812 - accuracy: 0.8838 - val_loss: 0.5695 - val_accuracy: 0.9026\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.3904 - accuracy: 0.9103 - val_loss: 0.5018 - val_accuracy: 0.9126\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3507 - accuracy: 0.9127 - val_loss: 0.4423 - val_accuracy: 0.9043\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3227 - accuracy: 0.9125 - val_loss: 0.3943 - val_accuracy: 0.8948\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2984 - accuracy: 0.9119 - val_loss: 0.3653 - val_accuracy: 0.8823\n",
      "Training fold 4 for question number 9\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 148ms/step - loss: 0.5867 - accuracy: 0.8185 - val_loss: 0.5909 - val_accuracy: 0.8459\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4001 - accuracy: 0.9004 - val_loss: 0.5153 - val_accuracy: 0.8759\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3577 - accuracy: 0.9107 - val_loss: 0.4455 - val_accuracy: 0.9059\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3266 - accuracy: 0.9119 - val_loss: 0.3947 - val_accuracy: 0.9159\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3057 - accuracy: 0.9122 - val_loss: 0.3581 - val_accuracy: 0.9159\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2854 - accuracy: 0.9120 - val_loss: 0.3252 - val_accuracy: 0.9159\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2675 - accuracy: 0.9120 - val_loss: 0.2994 - val_accuracy: 0.9112\n",
      "Training fold 5 for question number 9\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 143ms/step - loss: 0.4849 - accuracy: 0.8730 - val_loss: 0.5615 - val_accuracy: 0.8983\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3954 - accuracy: 0.9065 - val_loss: 0.4958 - val_accuracy: 0.9183\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3540 - accuracy: 0.9103 - val_loss: 0.4442 - val_accuracy: 0.9131\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3211 - accuracy: 0.9111 - val_loss: 0.3996 - val_accuracy: 0.9098\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3001 - accuracy: 0.9101 - val_loss: 0.3707 - val_accuracy: 0.8781\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4933 - accuracy: 0.9231\n",
      "5/5 [==============================] - 2s 9ms/step\n",
      "##### Training for q_no 10 grp 5-12\n",
      "Training fold 1 for question number 10\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 146ms/step - loss: 0.6183 - accuracy: 0.7580 - val_loss: 0.6148 - val_accuracy: 0.8397\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.5212 - accuracy: 0.8120 - val_loss: 0.5386 - val_accuracy: 0.8393\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4659 - accuracy: 0.8294 - val_loss: 0.4803 - val_accuracy: 0.8403\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4217 - accuracy: 0.8350 - val_loss: 0.4341 - val_accuracy: 0.8403\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3855 - accuracy: 0.8377 - val_loss: 0.4000 - val_accuracy: 0.8403\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3549 - accuracy: 0.8369 - val_loss: 0.3639 - val_accuracy: 0.8403\n",
      "Training fold 2 for question number 10\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 147ms/step - loss: 0.6103 - accuracy: 0.7572 - val_loss: 0.6367 - val_accuracy: 0.8255\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5290 - accuracy: 0.8187 - val_loss: 0.5585 - val_accuracy: 0.8455\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4744 - accuracy: 0.8328 - val_loss: 0.4978 - val_accuracy: 0.8450\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4310 - accuracy: 0.8369 - val_loss: 0.4482 - val_accuracy: 0.8360\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3931 - accuracy: 0.8388 - val_loss: 0.4058 - val_accuracy: 0.8350\n",
      "Training fold 3 for question number 10\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 14s 151ms/step - loss: 0.6211 - accuracy: 0.7571 - val_loss: 0.6127 - val_accuracy: 0.8403\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.5256 - accuracy: 0.8127 - val_loss: 0.5455 - val_accuracy: 0.8440\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4682 - accuracy: 0.8309 - val_loss: 0.4871 - val_accuracy: 0.8406\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4229 - accuracy: 0.8370 - val_loss: 0.4363 - val_accuracy: 0.8397\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3871 - accuracy: 0.8373 - val_loss: 0.3950 - val_accuracy: 0.8397\n",
      "Training fold 4 for question number 10\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 144ms/step - loss: 0.6086 - accuracy: 0.7820 - val_loss: 0.6193 - val_accuracy: 0.8429\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5226 - accuracy: 0.8223 - val_loss: 0.5560 - val_accuracy: 0.8425\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4720 - accuracy: 0.8342 - val_loss: 0.4977 - val_accuracy: 0.8442\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4288 - accuracy: 0.8370 - val_loss: 0.4443 - val_accuracy: 0.8385\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3915 - accuracy: 0.8385 - val_loss: 0.3986 - val_accuracy: 0.8385\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3593 - accuracy: 0.8378 - val_loss: 0.3647 - val_accuracy: 0.8385\n",
      "Training fold 5 for question number 10\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 149ms/step - loss: 0.6315 - accuracy: 0.7643 - val_loss: 0.6225 - val_accuracy: 0.8199\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.5254 - accuracy: 0.8118 - val_loss: 0.5512 - val_accuracy: 0.8399\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4700 - accuracy: 0.8282 - val_loss: 0.4906 - val_accuracy: 0.8381\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4247 - accuracy: 0.8360 - val_loss: 0.4382 - val_accuracy: 0.8379\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3887 - accuracy: 0.8387 - val_loss: 0.3969 - val_accuracy: 0.8422\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3565 - accuracy: 0.8408 - val_loss: 0.3632 - val_accuracy: 0.8422\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3323 - accuracy: 0.8385 - val_loss: 0.3360 - val_accuracy: 0.8422\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3099 - accuracy: 0.8400 - val_loss: 0.3208 - val_accuracy: 0.8422\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3983 - accuracy: 0.8366\n",
      "5/5 [==============================] - 2s 12ms/step\n",
      "##### Training for q_no 11 grp 5-12\n",
      "Training fold 1 for question number 11\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 143ms/step - loss: 0.5698 - accuracy: 0.8172 - val_loss: 0.5938 - val_accuracy: 0.8900\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4565 - accuracy: 0.8708 - val_loss: 0.5237 - val_accuracy: 0.8900\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4108 - accuracy: 0.8776 - val_loss: 0.4661 - val_accuracy: 0.8836\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3770 - accuracy: 0.8797 - val_loss: 0.4200 - val_accuracy: 0.8766\n",
      "Training fold 2 for question number 11\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 148ms/step - loss: 0.5721 - accuracy: 0.8321 - val_loss: 0.6013 - val_accuracy: 0.8222\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4522 - accuracy: 0.8765 - val_loss: 0.5312 - val_accuracy: 0.8800\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4061 - accuracy: 0.8806 - val_loss: 0.4655 - val_accuracy: 0.8717\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3692 - accuracy: 0.8815 - val_loss: 0.4156 - val_accuracy: 0.8646\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3416 - accuracy: 0.8807 - val_loss: 0.3825 - val_accuracy: 0.7983\n",
      "Training fold 3 for question number 11\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 144ms/step - loss: 0.5468 - accuracy: 0.8307 - val_loss: 0.6016 - val_accuracy: 0.8854\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4518 - accuracy: 0.8762 - val_loss: 0.5398 - val_accuracy: 0.8678\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4082 - accuracy: 0.8804 - val_loss: 0.4905 - val_accuracy: 0.8177\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3742 - accuracy: 0.8814 - val_loss: 0.4536 - val_accuracy: 0.7946\n",
      "Training fold 4 for question number 11\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 143ms/step - loss: 0.5480 - accuracy: 0.8265 - val_loss: 0.6037 - val_accuracy: 0.8625\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4533 - accuracy: 0.8766 - val_loss: 0.5280 - val_accuracy: 0.8825\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4071 - accuracy: 0.8815 - val_loss: 0.4675 - val_accuracy: 0.8805\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3719 - accuracy: 0.8830 - val_loss: 0.4214 - val_accuracy: 0.8771\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3442 - accuracy: 0.8824 - val_loss: 0.3868 - val_accuracy: 0.8620\n",
      "Training fold 5 for question number 11\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 146ms/step - loss: 0.5628 - accuracy: 0.8139 - val_loss: 0.5869 - val_accuracy: 0.8878\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.4535 - accuracy: 0.8740 - val_loss: 0.5270 - val_accuracy: 0.8816\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4077 - accuracy: 0.8795 - val_loss: 0.4719 - val_accuracy: 0.8734\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3722 - accuracy: 0.8815 - val_loss: 0.4280 - val_accuracy: 0.8497\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5863 - accuracy: 0.8887\n",
      "5/5 [==============================] - 2s 8ms/step\n",
      "##### Training for q_no 12 grp 5-12\n",
      "Training fold 1 for question number 12\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 142ms/step - loss: 0.3399 - accuracy: 0.9235 - val_loss: 0.5339 - val_accuracy: 0.8974\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.2657 - accuracy: 0.9536 - val_loss: 0.4495 - val_accuracy: 0.9274\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2392 - accuracy: 0.9548 - val_loss: 0.3822 - val_accuracy: 0.9474\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2204 - accuracy: 0.9551 - val_loss: 0.3234 - val_accuracy: 0.9574\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2055 - accuracy: 0.9550 - val_loss: 0.2898 - val_accuracy: 0.9574\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1915 - accuracy: 0.9549 - val_loss: 0.2581 - val_accuracy: 0.9574\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1818 - accuracy: 0.9547 - val_loss: 0.2342 - val_accuracy: 0.9574\n",
      "Training fold 2 for question number 12\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 141ms/step - loss: 0.3467 - accuracy: 0.9183 - val_loss: 0.5185 - val_accuracy: 0.9094\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2649 - accuracy: 0.9536 - val_loss: 0.4270 - val_accuracy: 0.9393\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.2414 - accuracy: 0.9545 - val_loss: 0.3553 - val_accuracy: 0.9593\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.2206 - accuracy: 0.9545 - val_loss: 0.2999 - val_accuracy: 0.9593\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2033 - accuracy: 0.9545 - val_loss: 0.2607 - val_accuracy: 0.9593\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1921 - accuracy: 0.9541 - val_loss: 0.2306 - val_accuracy: 0.9529\n",
      "Training fold 3 for question number 12\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 144ms/step - loss: 0.3236 - accuracy: 0.9342 - val_loss: 0.5192 - val_accuracy: 0.9237\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2603 - accuracy: 0.9556 - val_loss: 0.4420 - val_accuracy: 0.9337\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2373 - accuracy: 0.9560 - val_loss: 0.3757 - val_accuracy: 0.9537\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2194 - accuracy: 0.9560 - val_loss: 0.3180 - val_accuracy: 0.9537\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2062 - accuracy: 0.9559 - val_loss: 0.2756 - val_accuracy: 0.9537\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1927 - accuracy: 0.9558 - val_loss: 0.2464 - val_accuracy: 0.9473\n",
      "Training fold 4 for question number 12\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 14s 145ms/step - loss: 0.3776 - accuracy: 0.8989 - val_loss: 0.5133 - val_accuracy: 0.9242\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2668 - accuracy: 0.9546 - val_loss: 0.4387 - val_accuracy: 0.9342\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2416 - accuracy: 0.9557 - val_loss: 0.3785 - val_accuracy: 0.9542\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2231 - accuracy: 0.9558 - val_loss: 0.3318 - val_accuracy: 0.9542\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2066 - accuracy: 0.9560 - val_loss: 0.2930 - val_accuracy: 0.9542\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1931 - accuracy: 0.9559 - val_loss: 0.2656 - val_accuracy: 0.9542\n",
      "Training fold 5 for question number 12\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 148ms/step - loss: 0.3643 - accuracy: 0.9070 - val_loss: 0.5356 - val_accuracy: 0.9137\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.2636 - accuracy: 0.9554 - val_loss: 0.4632 - val_accuracy: 0.9336\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2399 - accuracy: 0.9560 - val_loss: 0.4051 - val_accuracy: 0.9536\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2224 - accuracy: 0.9561 - val_loss: 0.3533 - val_accuracy: 0.9536\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2076 - accuracy: 0.9561 - val_loss: 0.3139 - val_accuracy: 0.9536\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1942 - accuracy: 0.9561 - val_loss: 0.2832 - val_accuracy: 0.9458\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3997 - accuracy: 0.9586\n",
      "5/5 [==============================] - 2s 8ms/step\n",
      "##### Training for q_no 13 grp 5-12\n",
      "Training fold 1 for question number 13\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 141ms/step - loss: 0.7040 - accuracy: 0.6281 - val_loss: 0.5897 - val_accuracy: 0.9131\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5913 - accuracy: 0.7116 - val_loss: 0.5189 - val_accuracy: 0.9131\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5186 - accuracy: 0.7747 - val_loss: 0.4605 - val_accuracy: 0.9131\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4604 - accuracy: 0.8125 - val_loss: 0.4090 - val_accuracy: 0.9131\n",
      "Training fold 2 for question number 13\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 142ms/step - loss: 0.7030 - accuracy: 0.6417 - val_loss: 0.6554 - val_accuracy: 0.6992\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5905 - accuracy: 0.7291 - val_loss: 0.5497 - val_accuracy: 0.7850\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5211 - accuracy: 0.7831 - val_loss: 0.4780 - val_accuracy: 0.9113\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4641 - accuracy: 0.8143 - val_loss: 0.4139 - val_accuracy: 0.9113\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4140 - accuracy: 0.8362 - val_loss: 0.3638 - val_accuracy: 0.9113\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3709 - accuracy: 0.8536 - val_loss: 0.3199 - val_accuracy: 0.9113\n",
      "Training fold 3 for question number 13\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 145ms/step - loss: 0.6972 - accuracy: 0.6358 - val_loss: 0.6491 - val_accuracy: 0.7494\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.5921 - accuracy: 0.7234 - val_loss: 0.5550 - val_accuracy: 0.8691\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.5222 - accuracy: 0.7760 - val_loss: 0.4895 - val_accuracy: 0.9114\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4625 - accuracy: 0.8133 - val_loss: 0.4280 - val_accuracy: 0.9114\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4121 - accuracy: 0.8344 - val_loss: 0.3712 - val_accuracy: 0.9114\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3637 - accuracy: 0.8556 - val_loss: 0.3269 - val_accuracy: 0.9114\n",
      "Training fold 4 for question number 13\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 144ms/step - loss: 0.7024 - accuracy: 0.6230 - val_loss: 0.6045 - val_accuracy: 0.8761\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5920 - accuracy: 0.7115 - val_loss: 0.5292 - val_accuracy: 0.9134\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.5213 - accuracy: 0.7701 - val_loss: 0.4652 - val_accuracy: 0.9134\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4595 - accuracy: 0.8078 - val_loss: 0.4048 - val_accuracy: 0.9134\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4070 - accuracy: 0.8353 - val_loss: 0.3589 - val_accuracy: 0.9134\n",
      "Training fold 5 for question number 13\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 142ms/step - loss: 0.6853 - accuracy: 0.6517 - val_loss: 0.6434 - val_accuracy: 0.7811\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5924 - accuracy: 0.7321 - val_loss: 0.5734 - val_accuracy: 0.8558\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.5266 - accuracy: 0.7833 - val_loss: 0.5030 - val_accuracy: 0.9149\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4663 - accuracy: 0.8143 - val_loss: 0.4382 - val_accuracy: 0.9149\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4148 - accuracy: 0.8334 - val_loss: 0.3795 - val_accuracy: 0.9149\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3655 - accuracy: 0.8520 - val_loss: 0.3296 - val_accuracy: 0.9149\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5043 - accuracy: 0.9096\n",
      "5/5 [==============================] - 2s 8ms/step\n",
      "##### Training for q_no 14 grp 13-22\n",
      "Training fold 1 for question number 14\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 11s 151ms/step - loss: 0.5283 - accuracy: 0.8473 - val_loss: 0.5857 - val_accuracy: 0.8769\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4157 - accuracy: 0.8978 - val_loss: 0.4981 - val_accuracy: 0.9069\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3749 - accuracy: 0.9017 - val_loss: 0.4424 - val_accuracy: 0.9025\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3438 - accuracy: 0.9025 - val_loss: 0.3980 - val_accuracy: 0.8933\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3197 - accuracy: 0.9023 - val_loss: 0.3651 - val_accuracy: 0.8814\n",
      "Training fold 2 for question number 14\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 143ms/step - loss: 0.5093 - accuracy: 0.8505 - val_loss: 0.5989 - val_accuracy: 0.9062\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4144 - accuracy: 0.8973 - val_loss: 0.5283 - val_accuracy: 0.9062\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3758 - accuracy: 0.9014 - val_loss: 0.4696 - val_accuracy: 0.9016\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3439 - accuracy: 0.9024 - val_loss: 0.4221 - val_accuracy: 0.8945\n",
      "Training fold 3 for question number 14\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 143ms/step - loss: 0.4685 - accuracy: 0.8894 - val_loss: 0.6115 - val_accuracy: 0.8051\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4094 - accuracy: 0.9025 - val_loss: 0.5403 - val_accuracy: 0.9051\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3730 - accuracy: 0.9033 - val_loss: 0.4798 - val_accuracy: 0.9051\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3463 - accuracy: 0.9032 - val_loss: 0.4269 - val_accuracy: 0.9003\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3184 - accuracy: 0.9022 - val_loss: 0.3842 - val_accuracy: 0.8932\n",
      "Training fold 4 for question number 14\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 142ms/step - loss: 0.5145 - accuracy: 0.8485 - val_loss: 0.5899 - val_accuracy: 0.8327\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4145 - accuracy: 0.8966 - val_loss: 0.5082 - val_accuracy: 0.9031\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3744 - accuracy: 0.9023 - val_loss: 0.4525 - val_accuracy: 0.9031\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3434 - accuracy: 0.9034 - val_loss: 0.4078 - val_accuracy: 0.8977\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3203 - accuracy: 0.9036 - val_loss: 0.3727 - val_accuracy: 0.8930\n",
      "Training fold 5 for question number 14\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 142ms/step - loss: 0.4814 - accuracy: 0.8740 - val_loss: 0.5946 - val_accuracy: 0.8831\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4109 - accuracy: 0.8983 - val_loss: 0.5237 - val_accuracy: 0.9029\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3709 - accuracy: 0.9026 - val_loss: 0.4721 - val_accuracy: 0.8919\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3386 - accuracy: 0.9031 - val_loss: 0.4248 - val_accuracy: 0.8892\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3146 - accuracy: 0.9031 - val_loss: 0.3910 - val_accuracy: 0.8244\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5193 - accuracy: 0.9140\n",
      "5/5 [==============================] - 2s 9ms/step\n",
      "##### Training for q_no 15 grp 13-22\n",
      "Training fold 1 for question number 15\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 143ms/step - loss: 0.6854 - accuracy: 0.7217 - val_loss: 0.6352 - val_accuracy: 0.7608\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.5375 - accuracy: 0.8075 - val_loss: 0.5509 - val_accuracy: 0.8302\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4807 - accuracy: 0.8197 - val_loss: 0.4876 - val_accuracy: 0.8471\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4339 - accuracy: 0.8311 - val_loss: 0.4397 - val_accuracy: 0.8471\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3975 - accuracy: 0.8348 - val_loss: 0.4019 - val_accuracy: 0.8471\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3671 - accuracy: 0.8345 - val_loss: 0.3712 - val_accuracy: 0.8471\n",
      "Training fold 2 for question number 15\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 14s 141ms/step - loss: 0.6324 - accuracy: 0.7464 - val_loss: 0.6210 - val_accuracy: 0.8101\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5347 - accuracy: 0.8062 - val_loss: 0.5461 - val_accuracy: 0.8311\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4796 - accuracy: 0.8245 - val_loss: 0.4858 - val_accuracy: 0.8352\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4353 - accuracy: 0.8317 - val_loss: 0.4370 - val_accuracy: 0.8504\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3945 - accuracy: 0.8334 - val_loss: 0.3963 - val_accuracy: 0.8504\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3626 - accuracy: 0.8370 - val_loss: 0.3537 - val_accuracy: 0.8504\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3362 - accuracy: 0.8350 - val_loss: 0.3315 - val_accuracy: 0.8504\n",
      "Training fold 3 for question number 15\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 140ms/step - loss: 0.6315 - accuracy: 0.7520 - val_loss: 0.6061 - val_accuracy: 0.8339\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.5359 - accuracy: 0.7972 - val_loss: 0.5397 - val_accuracy: 0.8325\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4809 - accuracy: 0.8176 - val_loss: 0.4825 - val_accuracy: 0.8327\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4349 - accuracy: 0.8272 - val_loss: 0.4308 - val_accuracy: 0.8471\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3953 - accuracy: 0.8310 - val_loss: 0.3862 - val_accuracy: 0.8471\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3602 - accuracy: 0.8353 - val_loss: 0.3537 - val_accuracy: 0.8471\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3312 - accuracy: 0.8346 - val_loss: 0.3263 - val_accuracy: 0.8471\n",
      "Training fold 4 for question number 15\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 140ms/step - loss: 0.6195 - accuracy: 0.7563 - val_loss: 0.6124 - val_accuracy: 0.8425\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.5339 - accuracy: 0.8060 - val_loss: 0.5536 - val_accuracy: 0.8425\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.4815 - accuracy: 0.8240 - val_loss: 0.5027 - val_accuracy: 0.8425\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4386 - accuracy: 0.8283 - val_loss: 0.4620 - val_accuracy: 0.8425\n",
      "Training fold 5 for question number 15\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 151ms/step - loss: 0.6308 - accuracy: 0.7464 - val_loss: 0.6403 - val_accuracy: 0.7444\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.5389 - accuracy: 0.8069 - val_loss: 0.5626 - val_accuracy: 0.8259\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.4847 - accuracy: 0.8214 - val_loss: 0.5082 - val_accuracy: 0.8480\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4409 - accuracy: 0.8279 - val_loss: 0.4593 - val_accuracy: 0.8480\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4020 - accuracy: 0.8325 - val_loss: 0.4133 - val_accuracy: 0.8480\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3686 - accuracy: 0.8357 - val_loss: 0.3767 - val_accuracy: 0.8480\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5090 - accuracy: 0.8441\n",
      "5/5 [==============================] - 2s 8ms/step\n",
      "##### Training for q_no 16 grp 13-22\n",
      "Training fold 1 for question number 16\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 143ms/step - loss: 0.4755 - accuracy: 0.8669 - val_loss: 0.5667 - val_accuracy: 0.8941\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3892 - accuracy: 0.9098 - val_loss: 0.4991 - val_accuracy: 0.9141\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3491 - accuracy: 0.9126 - val_loss: 0.4432 - val_accuracy: 0.9141\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3201 - accuracy: 0.9123 - val_loss: 0.4030 - val_accuracy: 0.8947\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2983 - accuracy: 0.9113 - val_loss: 0.3668 - val_accuracy: 0.8798\n",
      "Training fold 2 for question number 16\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 142ms/step - loss: 0.4432 - accuracy: 0.9000 - val_loss: 0.6161 - val_accuracy: 0.7836\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3888 - accuracy: 0.9124 - val_loss: 0.5382 - val_accuracy: 0.8436\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3538 - accuracy: 0.9133 - val_loss: 0.4712 - val_accuracy: 0.9036\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3240 - accuracy: 0.9136 - val_loss: 0.4216 - val_accuracy: 0.9136\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3001 - accuracy: 0.9118 - val_loss: 0.3704 - val_accuracy: 0.9053\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2790 - accuracy: 0.9114 - val_loss: 0.3421 - val_accuracy: 0.8788\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2604 - accuracy: 0.9105 - val_loss: 0.3100 - val_accuracy: 0.8700\n",
      "Training fold 3 for question number 16\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 145ms/step - loss: 0.4829 - accuracy: 0.8648 - val_loss: 0.5885 - val_accuracy: 0.8636\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3945 - accuracy: 0.9077 - val_loss: 0.5168 - val_accuracy: 0.8936\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3568 - accuracy: 0.9121 - val_loss: 0.4564 - val_accuracy: 0.9136\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3270 - accuracy: 0.9130 - val_loss: 0.4120 - val_accuracy: 0.9038\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3045 - accuracy: 0.9133 - val_loss: 0.3780 - val_accuracy: 0.8938\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2836 - accuracy: 0.9127 - val_loss: 0.3487 - val_accuracy: 0.8855\n",
      "Training fold 4 for question number 16\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 144ms/step - loss: 0.4946 - accuracy: 0.8760 - val_loss: 0.5758 - val_accuracy: 0.8751\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3904 - accuracy: 0.9059 - val_loss: 0.4844 - val_accuracy: 0.9151\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3491 - accuracy: 0.9108 - val_loss: 0.4286 - val_accuracy: 0.9151\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3204 - accuracy: 0.9120 - val_loss: 0.3904 - val_accuracy: 0.9002\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2956 - accuracy: 0.9115 - val_loss: 0.3597 - val_accuracy: 0.8761\n",
      "Training fold 5 for question number 16\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 144ms/step - loss: 0.4763 - accuracy: 0.8862 - val_loss: 0.6077 - val_accuracy: 0.7947\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3906 - accuracy: 0.9090 - val_loss: 0.5205 - val_accuracy: 0.8843\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3515 - accuracy: 0.9124 - val_loss: 0.4567 - val_accuracy: 0.9043\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3226 - accuracy: 0.9126 - val_loss: 0.4145 - val_accuracy: 0.9097\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2967 - accuracy: 0.9118 - val_loss: 0.3787 - val_accuracy: 0.9097\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2781 - accuracy: 0.9115 - val_loss: 0.3495 - val_accuracy: 0.9045\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2638 - accuracy: 0.9110 - val_loss: 0.3220 - val_accuracy: 0.7864\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4131 - accuracy: 0.9153\n",
      "5/5 [==============================] - 2s 9ms/step\n",
      "##### Training for q_no 17 grp 13-22\n",
      "Training fold 1 for question number 17\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 147ms/step - loss: 0.5086 - accuracy: 0.8520 - val_loss: 0.5700 - val_accuracy: 0.9005\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4243 - accuracy: 0.8924 - val_loss: 0.4991 - val_accuracy: 0.9005\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3842 - accuracy: 0.8941 - val_loss: 0.4381 - val_accuracy: 0.8954\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3523 - accuracy: 0.8953 - val_loss: 0.3927 - val_accuracy: 0.8903\n",
      "Training fold 2 for question number 17\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 143ms/step - loss: 0.5200 - accuracy: 0.8557 - val_loss: 0.5880 - val_accuracy: 0.8576\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.4276 - accuracy: 0.8883 - val_loss: 0.5132 - val_accuracy: 0.8876\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3786 - accuracy: 0.8939 - val_loss: 0.4545 - val_accuracy: 0.8944\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3451 - accuracy: 0.8950 - val_loss: 0.4085 - val_accuracy: 0.8867\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3172 - accuracy: 0.8965 - val_loss: 0.3725 - val_accuracy: 0.8188\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2960 - accuracy: 0.8961 - val_loss: 0.3458 - val_accuracy: 0.7829\n",
      "Training fold 3 for question number 17\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 142ms/step - loss: 0.5261 - accuracy: 0.8497 - val_loss: 0.6033 - val_accuracy: 0.7984\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4273 - accuracy: 0.8893 - val_loss: 0.5194 - val_accuracy: 0.8684\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3865 - accuracy: 0.8957 - val_loss: 0.4530 - val_accuracy: 0.8984\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3536 - accuracy: 0.8974 - val_loss: 0.4030 - val_accuracy: 0.8984\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3272 - accuracy: 0.8972 - val_loss: 0.3612 - val_accuracy: 0.8950\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3035 - accuracy: 0.8976 - val_loss: 0.3307 - val_accuracy: 0.8881\n",
      "Training fold 4 for question number 17\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 145ms/step - loss: 0.4955 - accuracy: 0.8662 - val_loss: 0.5877 - val_accuracy: 0.8601\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.4262 - accuracy: 0.8919 - val_loss: 0.5118 - val_accuracy: 0.8901\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3842 - accuracy: 0.8958 - val_loss: 0.4493 - val_accuracy: 0.9001\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.3534 - accuracy: 0.8966 - val_loss: 0.3986 - val_accuracy: 0.8958\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3281 - accuracy: 0.8951 - val_loss: 0.3568 - val_accuracy: 0.8933\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.3021 - accuracy: 0.8955 - val_loss: 0.3199 - val_accuracy: 0.8848\n",
      "Training fold 5 for question number 17\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 143ms/step - loss: 0.4856 - accuracy: 0.8731 - val_loss: 0.5880 - val_accuracy: 0.8884\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.4232 - accuracy: 0.8941 - val_loss: 0.5232 - val_accuracy: 0.8954\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3839 - accuracy: 0.8972 - val_loss: 0.4672 - val_accuracy: 0.8930\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3518 - accuracy: 0.8971 - val_loss: 0.4204 - val_accuracy: 0.8865\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3216 - accuracy: 0.8974 - val_loss: 0.3861 - val_accuracy: 0.7986\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5210 - accuracy: 0.9011\n",
      "5/5 [==============================] - 2s 12ms/step\n",
      "##### Training for q_no 18 grp 13-22\n",
      "Training fold 1 for question number 18\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 144ms/step - loss: 0.2613 - accuracy: 0.9221 - val_loss: 0.4526 - val_accuracy: 0.9459\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1357 - accuracy: 0.9837 - val_loss: 0.3762 - val_accuracy: 0.9559\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1263 - accuracy: 0.9837 - val_loss: 0.3140 - val_accuracy: 0.9659\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1196 - accuracy: 0.9837 - val_loss: 0.2601 - val_accuracy: 0.9759\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.1122 - accuracy: 0.9837 - val_loss: 0.2183 - val_accuracy: 0.9759\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1061 - accuracy: 0.9837 - val_loss: 0.1834 - val_accuracy: 0.9859\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1010 - accuracy: 0.9837 - val_loss: 0.1595 - val_accuracy: 0.9859\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.0954 - accuracy: 0.9837 - val_loss: 0.1392 - val_accuracy: 0.9859\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0918 - accuracy: 0.9837 - val_loss: 0.1268 - val_accuracy: 0.9859\n",
      "Training fold 2 for question number 18\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 16s 543ms/step - loss: 0.1700 - accuracy: 0.9720 - val_loss: 0.4388 - val_accuracy: 0.9539\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.1323 - accuracy: 0.9842 - val_loss: 0.3546 - val_accuracy: 0.9639\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1224 - accuracy: 0.9842 - val_loss: 0.2849 - val_accuracy: 0.9739\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1130 - accuracy: 0.9842 - val_loss: 0.2271 - val_accuracy: 0.9839\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1063 - accuracy: 0.9842 - val_loss: 0.1874 - val_accuracy: 0.9839\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0995 - accuracy: 0.9842 - val_loss: 0.1573 - val_accuracy: 0.9839\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.0936 - accuracy: 0.9842 - val_loss: 0.1341 - val_accuracy: 0.9839\n",
      "Training fold 3 for question number 18\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 145ms/step - loss: 0.1951 - accuracy: 0.9507 - val_loss: 0.4481 - val_accuracy: 0.9328\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1309 - accuracy: 0.9844 - val_loss: 0.3727 - val_accuracy: 0.9430\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1225 - accuracy: 0.9844 - val_loss: 0.3052 - val_accuracy: 0.9628\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1150 - accuracy: 0.9844 - val_loss: 0.2495 - val_accuracy: 0.9730\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1084 - accuracy: 0.9844 - val_loss: 0.2045 - val_accuracy: 0.9830\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1015 - accuracy: 0.9844 - val_loss: 0.1726 - val_accuracy: 0.9830\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.0958 - accuracy: 0.9844 - val_loss: 0.1511 - val_accuracy: 0.9830\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 31ms/step - loss: 0.0910 - accuracy: 0.9844 - val_loss: 0.1342 - val_accuracy: 0.9830\n",
      "Training fold 4 for question number 18\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 145ms/step - loss: 0.1911 - accuracy: 0.9531 - val_loss: 0.4391 - val_accuracy: 0.9544\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1340 - accuracy: 0.9841 - val_loss: 0.3586 - val_accuracy: 0.9644\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1239 - accuracy: 0.9841 - val_loss: 0.2934 - val_accuracy: 0.9744\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1159 - accuracy: 0.9841 - val_loss: 0.2387 - val_accuracy: 0.9844\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1098 - accuracy: 0.9841 - val_loss: 0.1957 - val_accuracy: 0.9844\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1015 - accuracy: 0.9841 - val_loss: 0.1637 - val_accuracy: 0.9844\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0959 - accuracy: 0.9841 - val_loss: 0.1384 - val_accuracy: 0.9844\n",
      "Training fold 5 for question number 18\n",
      "Epoch 1/10\n",
      "15/15 [==============================] - 10s 142ms/step - loss: 0.1835 - accuracy: 0.9585 - val_loss: 0.4701 - val_accuracy: 0.9136\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1331 - accuracy: 0.9843 - val_loss: 0.3946 - val_accuracy: 0.9336\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1241 - accuracy: 0.9843 - val_loss: 0.3263 - val_accuracy: 0.9536\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1148 - accuracy: 0.9843 - val_loss: 0.2664 - val_accuracy: 0.9636\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1081 - accuracy: 0.9843 - val_loss: 0.2170 - val_accuracy: 0.9736\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1010 - accuracy: 0.9843 - val_loss: 0.1784 - val_accuracy: 0.9836\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.0949 - accuracy: 0.9843 - val_loss: 0.1502 - val_accuracy: 0.9836\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.0902 - accuracy: 0.9843 - val_loss: 0.1292 - val_accuracy: 0.9836\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.0860 - accuracy: 0.9843 - val_loss: 0.1142 - val_accuracy: 0.9836\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.1766 - accuracy: 0.9846\n",
      "5/5 [==============================] - 2s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "k = 5  # Number of folds\n",
    "n_epochs = 10 # Needs to be raised \n",
    "batch_size = 32\n",
    "\n",
    "# Initialize lists for storing results\n",
    "test_loss_and_accuracy_list = []\n",
    "history_models = []\n",
    "models = {}\n",
    "f1_score_list = []\n",
    "\n",
    "# Initialize lists for storing all predictions and true labels\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "# Adjusted function to handle ragged sequences\n",
    "def dataset_to_numpy(ds, padding='post', maxlen=None):\n",
    "    X, y = [], []\n",
    "    for features, label in ds:\n",
    "        X.append(features.numpy())\n",
    "        y.append(label.numpy())\n",
    "    # Pad sequences if they are ragged\n",
    "    X_padded = pad_sequences(X, padding=padding, maxlen=maxlen, dtype='float32')\n",
    "    y_padded = pad_sequences(y, padding=padding, maxlen=maxlen, dtype='float32')\n",
    "    return X_padded, y_padded\n",
    "\n",
    "# KFold configuration\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "for q_no in range(1, 19):\n",
    "    # Select level group for the question based on the q_no.\n",
    "    if q_no <= 3:\n",
    "        grp = '0-4'\n",
    "    elif q_no <= 13:\n",
    "        grp = '5-12'\n",
    "    else:\n",
    "        grp = '13-22'\n",
    "    print(\"##### Training for q_no\", q_no, \"grp\", grp)\n",
    "    \n",
    "    maxlen = 100  # Assuming 100 time steps is sufficient\n",
    "\n",
    "    # Convert TensorFlow datasets to NumPy arrays with padding\n",
    "    X_train, y_train = dataset_to_numpy(train_set_list[q_no - 1], maxlen=maxlen)\n",
    "    X_valid, y_valid = dataset_to_numpy(valid_set_list[q_no - 1], maxlen=maxlen)\n",
    "    X_test, y_test = dataset_to_numpy(test_set_list[q_no - 1], maxlen=maxlen)\n",
    "\n",
    "    \n",
    "    # Combine training and validation data for k-fold\n",
    "    X_full = np.concatenate([X_train, X_valid], axis=0)\n",
    "    y_full = np.concatenate([y_train, y_valid], axis=0)\n",
    "\n",
    "    fold_no = 1\n",
    "    for train_index, val_index in kf.split(X_full):\n",
    "        print(f'Training fold {fold_no} for question number {q_no}')\n",
    "        X_train_fold, X_val_fold = X_full[train_index], X_full[val_index]\n",
    "        y_train_fold, y_val_fold = y_full[train_index], y_full[val_index]\n",
    "\n",
    "        # Define the model\n",
    "        model = Sequential([\n",
    "        Bidirectional(LSTM(64, return_sequences=True), input_shape=(100, 31)),\n",
    "        Dropout(0.2),\n",
    "        BatchNormalization(),\n",
    "        Bidirectional(LSTM(64, return_sequences=True)),\n",
    "        Dropout(0.2),\n",
    "        BatchNormalization(),\n",
    "        TimeDistributed(Dense(1, activation='sigmoid'))])\n",
    "\n",
    "\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        early_stopping = EarlyStopping(monitor='val_accuracy', mode='max', patience=3, restore_best_weights=True)\n",
    "\n",
    "        # Fit the model\n",
    "        history = model.fit(X_train_fold, y_train_fold, epochs=n_epochs, validation_data=(X_val_fold, y_val_fold), callbacks=[early_stopping])\n",
    "\n",
    "        # Save the model and its history\n",
    "        models[f'{grp}_{q_no}_fold{fold_no}'] = model\n",
    "        history_models.append(history)\n",
    "\n",
    "        fold_no += 1\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    results = model.evaluate(X_test, y_test)\n",
    "    test_loss_and_accuracy_list.append(results)\n",
    "\n",
    "    # Calculate and store F1 score\n",
    "    predictions = model.predict(X_test).round().astype(int).flatten()\n",
    "    f1_score_value = f1_score(y_test.flatten(), predictions, average='weighted')\n",
    "    f1_score_list.append(f1_score_value)\n",
    "\n",
    "    # Aggregate predictions and true labels\n",
    "    all_predictions.extend(predictions)\n",
    "    all_true_labels.extend(y_test.flatten())\n",
    "\n",
    "# Compute confusion matrix for all questions combined\n",
    "conf_matrix = confusion_matrix(all_true_labels, all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce97bddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:34:59.232032Z",
     "iopub.status.busy": "2024-04-09T18:34:59.230870Z",
     "iopub.status.idle": "2024-04-09T18:34:59.237527Z",
     "shell.execute_reply": "2024-04-09T18:34:59.236178Z"
    },
    "papermill": {
     "duration": 0.372019,
     "end_time": "2024-04-09T18:34:59.240332",
     "exception": false,
     "start_time": "2024-04-09T18:34:58.868313",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.908821573473863\n"
     ]
    }
   ],
   "source": [
    "average_f1_score = np.mean(f1_score_list)\n",
    "print(\"Average F1 Score:\", average_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ca24a46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:34:59.975610Z",
     "iopub.status.busy": "2024-04-09T18:34:59.974739Z",
     "iopub.status.idle": "2024-04-09T18:35:01.936800Z",
     "shell.execute_reply": "2024-04-09T18:35:01.935405Z"
    },
    "papermill": {
     "duration": 2.336677,
     "end_time": "2024-04-09T18:35:01.941473",
     "exception": false,
     "start_time": "2024-04-09T18:34:59.604796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "# Compute confusion matrix for all questions combined\n",
    "conf_matrix = confusion_matrix(all_true_labels, all_predictions)\n",
    "colors = [\"#FF0000\", \"#00FF00\", \"#FF0000\", \"#00FF00\"]  # red, green, red, green\n",
    "cmap = sns.color_palette(colors)\n",
    "\n",
    "# Plotting the confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.set(font_scale=1.4)  # Adjust font size\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap=cmap, cbar=False,\n",
    "            xticklabels=['TN', 'FP'], yticklabels=['FN', 'TP'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23cd2d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:35:02.661601Z",
     "iopub.status.busy": "2024-04-09T18:35:02.660317Z",
     "iopub.status.idle": "2024-04-09T18:35:02.684866Z",
     "shell.execute_reply": "2024-04-09T18:35:02.683555Z"
    },
    "papermill": {
     "duration": 0.3753,
     "end_time": "2024-04-09T18:35:02.687309",
     "exception": false,
     "start_time": "2024-04-09T18:35:02.312009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    F1 Score  Test Loss  Test Accuracy\n",
      "1   0.918810   0.462134       0.914730\n",
      "2   0.992256   0.113026       0.992230\n",
      "3   0.979517   0.232117       0.979324\n",
      "4   0.936029   0.424883       0.933716\n",
      "5   0.872007   0.615474       0.858446\n",
      "6   0.934597   0.474025       0.932162\n",
      "7   0.922739   0.441859       0.919122\n",
      "8   0.891686   0.463288       0.883176\n",
      "9   0.926336   0.493252       0.923108\n",
      "10  0.762199   0.398338       0.836622\n",
      "11  0.896297   0.586325       0.888716\n",
      "12  0.959476   0.399724       0.958649\n",
      "13  0.866532   0.504336       0.909595\n",
      "14  0.918151   0.519266       0.913987\n",
      "15  0.772675   0.508960       0.844054\n",
      "16  0.918705   0.413055       0.915338\n",
      "17  0.906078   0.521001       0.901081\n",
      "18  0.984699   0.176558       0.984595\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame for the scores\n",
    "scores_df = pd.DataFrame({\n",
    "    \"F1 Score\": f1_score_list,\n",
    "    \"Test Loss\": [result[0] for result in test_loss_and_accuracy_list],\n",
    "    \"Test Accuracy\": [result[1] for result in test_loss_and_accuracy_list]\n",
    "}, index=range(1, 19))  # Set the index to \"Question Number\"\n",
    "\n",
    "# Display the DataFrame\n",
    "print(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a07b2367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-09T18:35:03.432262Z",
     "iopub.status.busy": "2024-04-09T18:35:03.431391Z",
     "iopub.status.idle": "2024-04-09T18:35:03.853053Z",
     "shell.execute_reply": "2024-04-09T18:35:03.851992Z"
    },
    "papermill": {
     "duration": 0.826466,
     "end_time": "2024-04-09T18:35:03.855309",
     "exception": false,
     "start_time": "2024-04-09T18:35:03.028843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, 19), f1_score_list, color='skyblue')\n",
    "plt.xlabel('Question Number')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.title('F1 Score per Question')\n",
    "plt.xticks(range(1, 19))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 5748852,
     "sourceId": 45533,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30446,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1525.957808,
   "end_time": "2024-04-09T18:35:08.118599",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-09T18:09:42.160791",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
